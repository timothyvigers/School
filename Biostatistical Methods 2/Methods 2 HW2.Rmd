---
title: "Homework 2"
author: "Tim Vigers"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Model 1 equation estimates

### Strike 1
$$
ln(\text{odds}_\text{strike 1}) = ln(\frac{619}{1797}) = -1.066 = \hat{\beta_0}
$$

### Strike 2
$$
ln(\text{odds}_\text{strike 2}) = ln(\frac{355}{416}) = -0.159 = \hat{\beta_0} + \hat{\beta_1}
$$
$$
\hat{\beta_1} = -0.159 - \hat{\beta_0} = -0.159 - (-1.066) = 0.907
$$

### Strike 3
$$
ln(\text{odds}_\text{strike 3}) = ln(\frac{162}{569}) = -1.256 = \hat{\beta_0} + \hat{\beta_2}
$$
$$
\hat{\beta_2} = -1.256 - \hat{\beta_0} = -1.256 - (-1.066)= -0.190
$$

### Model 1
$$
\text{logit P (misconduct violation)} = \hat{\beta_0} + \hat{\beta_1}*\text{strikes 2} + \hat{\beta_2}*\text{strikes 3} = -1.066 + 0.907*\text{strikes 2} -0.190*\text{strikes 3}
$$

## 2. Log-likelihood for Model 1

$$
p1 = \frac{619}{2416}\\
p2 = \frac{355}{771}\\
p3 = \frac{162}{731}\\
$$
$$
LL = 619*ln(p1) + 1797*ln(1-p1) + 355*ln(p2) + 416*ln(1-p2) + 162*ln(p3) + 569*ln(1-p3) = -2293.492
$$

## 3. Log-likelihood for Model 0
### Calculate p estimate at the MLE
$$
\hat{p} = \frac{\text{number with misconduct}}{\text{total n}} = \frac{1136}{3918} = 0.290
$$

### Calculate log-likelihood estimate
$$
LL = \text{total number with misconduct}*ln(\hat{p}) + \text{total number without misconduct}*ln(1-\hat{p})=1136*ln(0.290) + 2782*ln(0.710) = -2359.033
$$

## 4. Perform a likelihood ratio test comparing Model 1 with Model 0
### Calculate the LRT statistic
$$
\text{LRT statistic} = 2(LL_{\text{model 1}} - LL_{\text{model 2}})=2(-2293.492-(-2359.033))=131.082
$$

This is a very high number for a chi square distribution with two degrees of freedom, so we can reject the null hypothesis. In this test, the null hypothesis is that B1 = B2 = 0, and our alternative hypothesis is that at least one of the coefficients is not equal to 0. In other words, model 1 is better than a model with just an intercept (model 0). 

## 5. Consider a model for this data where strikes enters as a linear term
$$
\hat{p} = \frac{e^{-0.99461+0.0627*\text{strike}}}{1+e^{-0.99461+0.0627*\text{strike}}}
$$
$$
\text{So, for a prisoner with 1 strike:}\\
\hat{p} = \frac{e^{-0.99461+0.0627*1}}{1+e^{-0.99461+0.0627*1}} = 0.283
$$
$$
\text{And for a prisoner with 3 strikes:}\\
\hat{p} = \frac{e^{-0.99461+0.0627*3}}{1+e^{-0.99461+0.0627*3}} = 0.309
$$

## 6. Relative odds using model 2
$$
\hat{OR} = \frac{e^{-0.99461+0.0627*3}}{e^{-0.99461+0.0627*1}} = e^{0.0627*(3-1)} = 1.134
$$

$$
\text{95% CI lower}= e^{0.0627*2-1.96(0.04439*2)} = 0.953\\
\text{95% CI upper}= e^{0.0627*2+1.96(0.04439*2)} = 1.349
$$

An increase of two strikes (from 1 to 3) raises the risk of a misconduct violation 1.13-fold (95% CI: 0.953,1.349). 

##7. Which model is better, Model 2 or Model 1?
### Grouped LL and AIC for model 1
$$
LL_{\text{grouped}}=ln\binom{2416}{619}+ln\binom{771}{355}+ln\binom{731}{162} -2293.492
$$
This needs to be calculated using R's logLik() function.
```{r}
# Create dataframe
dat <- as.data.frame(matrix(c(1,619,1797,
                              2,355,416,
                              3,162,569),
                            nrow = 3,ncol = 3,byrow = T))
colnames(dat) <- c("strikes", "y", "n")
dat$strikes <- as.factor(dat$strikes)
mod1 <- glm(cbind(y,n) ~ strikes,dat,family=binomial)
logLik(mod1)
```

$$
\text{AIC}_\text{model 1} = 2k - 2 LL = 6 - 2*(-10.870) = 27.74
$$

Check with R:
```{r}
summary(mod1)
```

Model 1 is better than model 2 based on AIC, because it has the lower AIC value and the difference is large enough to be considered significant (127.1).

## Code

```{r}
# Long data
dat_long <- reshape(dat,direction='long',varying=c('y','n'),
                    v.names='count',timevar='misconduct',times=1:0)
# Replicated data
dat_longrep <- dat_long[rep(1:6,dat_long$count),c('strikes','misconduct')]
# Check log-likelihood for model 1 (ungrouped)
ungroup_mod1 <- glm(misconduct ~ strikes,dat_longrep,family = binomial)
logLik(ungroup_mod1)
# LRT 
ungroup_mod0 <- glm(misconduct ~ 1,dat_longrep,family = binomial)
anova(ungroup_mod0,ungroup_mod1,test = "LRT")
1 - pchisq(131.082,2)
# Check model 2 predictions
mod2 <- glm(formula = cbind(y,n) ~ as.numeric(strikes), family = binomial,
            data = dat)
predict(mod2, newdata=list(strikes=c(1,3)),type = "response")
```