---
title: "Qualifying Exam 2019"
author: "Exam #7"
date: "6/6/2019"
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhead{}
- \renewcommand{\headrule}{}
- \fancyfoot[CO,CE]{Exam 7}
- \fancyfoot[RE,RO]{\thepage}
output: pdf_document
---

```{r setup,include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(epiR)
library(lme4)
library(nlme)
library(AER)
library(emmeans)
```

```{r echo=FALSE}
# Import datasets
fish <- read.csv("/Users/timvigers/Documents/School/Qualifying Exams/2019 MS/fishermen_mercury.csv")
pcbs <- read.csv("/Users/timvigers/Documents/School/Qualifying Exams/2019 MS/pcb_conc.csv")
hiv <- read.csv("/Users/timvigers/Documents/School/Qualifying Exams/2019 MS/hiv_comp_tall.csv",header = F)
colnames(hiv) <- c("pid","trt","week","logvl")
hiv$trt <- as.factor(hiv$trt)
hiv$pid <- as.factor(hiv$pid)
```

# Question 1

## a) Number of meals involving fish as a positive test

```{r echo=FALSE}
# Create indicator variables and response
fish$meal0 <- ifelse(fish$fishmlwk >= 0,1,0)
fish$meal1 <- ifelse(fish$fishmlwk >= 1,1,0)
fish$meal2 <- ifelse(fish$fishmlwk >= 2,1,0)
fish$meal3 <- ifelse(fish$fishmlwk >= 3,1,0)
fish$meal4 <- ifelse(fish$fishmlwk >= 4,1,0)
fish$meal7 <- ifelse(fish$fishmlwk >= 7,1,0)
fish$meal14 <- ifelse(fish$fishmlwk >= 14,1,0)
fish$meal21 <- ifelse(fish$fishmlwk >= 21,1,0)
fish$response <- ifelse(fish$MeHg >= 8,1,0)
# Create contingency tables
ctable0 <- table(factor(fish$meal0,levels=1:0),factor(fish$response,levels=1:0))
ctable1 <- table(factor(fish$meal1,levels=1:0),factor(fish$response,levels=1:0))
ctable2 <- table(factor(fish$meal2,levels=1:0),factor(fish$response,levels=1:0))
ctable3 <- table(factor(fish$meal3,levels=1:0),factor(fish$response,levels=1:0))
ctable4 <- table(factor(fish$meal4,levels=1:0),factor(fish$response,levels=1:0))
ctable7 <- table(factor(fish$meal7,levels=1:0),factor(fish$response,levels=1:0))
ctable14 <- table(factor(fish$meal14,levels=1:0),factor(fish$response,levels=1:0))
ctable21 <- table(factor(fish$meal21,levels=1:0),factor(fish$response,levels=1:0))
# Make results table
sens_spec_results <- as.data.frame(matrix(ncol = 2,nrow = 8))
colnames(sens_spec_results) <- c("Sensitivity","Specificity")
rownames(sens_spec_results) <- c(">=0",">=1",">=2",">=3",">=4",">=7",">=14",">=21")
```

```{r}
# epiR package for calculating sensitivity and specificity using contingency tables
sensspec0 <- epi.tests(ctable0)
sensspec1 <- epi.tests(ctable1)
sensspec2 <- epi.tests(ctable2)
sensspec3 <- epi.tests(ctable3)
sensspec4 <- epi.tests(ctable4)
sensspec7 <- epi.tests(ctable7)
sensspec14 <- epi.tests(ctable14)
sensspec21 <- epi.tests(ctable21)
```

```{r echo=FALSE}
# Format results
sens_spec_results[">=0","Specificity"] <- 
  round(sensspec0$elements$specificity$est*100,1)
sens_spec_results[">=0","Sensitivity"] <- 
  round(sensspec0$elements$sensitivity$est*100,1)
sens_spec_results[">=1","Specificity"] <- 
  round(sensspec1$elements$specificity$est*100,1)
sens_spec_results[">=1","Sensitivity"] <- 
  round(sensspec1$elements$sensitivity$est*100,1)
sens_spec_results[">=2","Specificity"] <- 
  round(sensspec2$elements$specificity$est*100,1)
sens_spec_results[">=2","Sensitivity"] <- 
  round(sensspec2$elements$sensitivity$est*100,1)
sens_spec_results[">=3","Specificity"] <- 
  round(sensspec3$elements$specificity$est*100,1)
sens_spec_results[">=3","Sensitivity"] <- 
  round(sensspec3$elements$sensitivity$est*100,1)
sens_spec_results[">=4","Specificity"] <- 
  round(sensspec4$elements$specificity$est*100,1)
sens_spec_results[">=4","Sensitivity"] <- 
  round(sensspec4$elements$sensitivity$est*100,1)
sens_spec_results[">=7","Specificity"] <- 
  round(sensspec7$elements$specificity$est*100,1)
sens_spec_results[">=7","Sensitivity"] <- 
  round(sensspec7$elements$sensitivity$est*100,1)
sens_spec_results[">=14","Specificity"] <- 
  round(sensspec14$elements$specificity$est*100,1)
sens_spec_results[">=14","Sensitivity"] <- 
  round(sensspec14$elements$sensitivity$est*100,1)
sens_spec_results[">=21","Specificity"] <- 
  round(sensspec21$elements$specificity$est*100,1)
sens_spec_results[">=21","Sensitivity"] <- 
  round(sensspec21$elements$sensitivity$est*100,1)
kable(sens_spec_results)
```

## b) Appropriate thresholds

Sensitivity refers to the true positive rate, or the probability that a test will rule in disease correctly. Specificity indicates the true negative rate, or the probability that a test will correctly rule out disease. Therefore, the probability of a false negative is 100 - sensitivity and the the false positive rate is 100 - specificity.

### i. True positives

If we want to maximize true positives while minimizing false positives, the optimal threshold is the one with the highest sensitivity and lowest 100 - specificity. A threshold of >= 3 meals per week including fish would provide a 100% true positive rate and a 72% false negative rate.

### ii. True negatives

Maximizing true negatives first and then true positives requires choosing the test with highest specificity and highest sensitivity. In this case a threshold of >= 21 meals including fish per week would provide a true negative detection rate of 93.6% and a true positive rate of 30%. 

## c) Bootstrap sampling for >= 21 meals threshold

```{r echo=FALSE}
# Vector for storing results
set.seed(1234)
B <- 10000
sens_results <- numeric(B)
spec_results <- numeric(B)
# Loop
for (i in 1:B) {
  meals <- sample(fish$fishmlwk,replace = T)
  meals <- ifelse(meals >= 21,1,0)
  response <- sample(fish$MeHg,replace = T)
  response <- ifelse(response >= 8,1,0)
  table <- table(factor(meals,levels=1:0),factor(response,levels=1:0))
  sens_results[i] <- (table[1,1]/sum(table[,1])) * 100
  spec_results[i] <- (table[2,2]/sum(table[,2])) * 100
}
```

### i. Plots

```{r echo=FALSE}
hist(sens_results,main = "Sensitivity Bootstrap Distribution",xlab = "Sensitivity")
```

```{r echo=FALSE}
hist(spec_results,main = "Specificity Bootstrap Distribution",xlab = "Specificity")
```

### ii. Mean, SE, and Bias From Bootstrap Distributions

```{r echo=FALSE}
boot_results <- as.data.frame(matrix(ncol = 3,nrow = 2))
colnames(boot_results) <- c("Mean","Standard Error","Bias")
rownames(boot_results) <- c("Sensitivity","Specificity")
# Sensitivity
boot_results["Sensitivity","Mean"] <- mean(sens_results)
boot_results["Sensitivity","Standard Error"] <- 
  sd(sens_results)/sqrt(length(sens_results))
boot_results["Sensitivity","Bias"] <- 
  mean(sens_results) - sensspec21$elements$sensitivity$est*100
# Specificity
boot_results["Specificity","Mean"] <- mean(spec_results)
boot_results["Specificity","Standard Error"] <- 
  sd(spec_results)/sqrt(length(spec_results))
boot_results["Specificity","Bias"] <- 
  mean(spec_results) - sensspec21$elements$specificity$est*100
kable(boot_results)
```

### iii. 90% Bootstrap and Normal Percentile Confidence Intervals

```{r include=FALSE}
# Sensitivity
# Normal percentiles
L <- mean(sens_results) - (1.645 * sd(sens_results))
U <- mean(sens_results) + (1.645 * sd(sens_results))
# Specificity
# Normal percentiles
Lc <- mean(spec_results) - (1.645 * sd(spec_results))
Uc <- mean(spec_results) + (1.645 * sd(spec_results))
# Results table
results <- as.data.frame(matrix(ncol = 3,nrow = 2))
rownames(results) <- c("Sensitivity","Specificity")
colnames(results) <- c("Normal Percentile","Coverage","Bootstrap CI")
L <- round(L,2)
U <- round(U,2)
Lc <- round(Lc,2)
Uc <- round(Uc,2)
results["Sensitivity",] <- 
  c(paste0(L,"%, ",U,"%"),
    paste0(round(sum(sens_results < L)/B * 100,2),"%, ",
           round(sum(sens_results > U)/B * 100,2),"%"),
    paste0(paste(round(quantile(sens_results,c(0.05,0.95)),2),collapse = "%, "),"%"))
results["Specificity",] <- 
  c(paste0(Lc,"%, ",Uc,"%"),
    paste0(round(sum(spec_results < Lc)/B * 100,2),"%, ",
           round(sum(spec_results > Uc)/B * 100,2),"%"),
    paste0(paste(round(quantile(spec_results,c(0.05,0.95)),2),collapse = "%, "),"%"))
```

```{r echo=FALSE}
kable(results)
```

The bootstrap distribution for sensitivity is not at all normal. The 90% confidence interval for this distribution using normal percentiles is (-7.00%, 23.34%), which does not make sense as sensitivity cannot be negative. Also, none of the bootstrap values were below the lower limit (again, because this is impossible), when we'd expect that 5% would be for a normal distribution. So in this case it would probably be better to use the bootstrap confidence interval (0%, 25%). 

The bootstrap distribution for specificity appears to be much closer to normal than for sensitivity. The 90% normal percentile confidence interval is (87.92%, 95.83%), which matches the bootstrap confidence interval very closely (87.80%, 95.80%). Also, approximately 5% percent of the bootstrap values were in each tail, which is what we would expect from a normal distribution.

## d. 90% Confidence Intervals Using Exact and Asymptotic Methods

```{r include=FALSE}
# Sensitivity
# Clopper-Pearson
results <- as.data.frame(matrix(ncol = 2,nrow = 2))
rownames(results) <- c("Sensitivity","Specificity")
colnames(results) <- c("Clopper-Pearson","Simple Asymptotic")
n <- sum(ctable21[,1])
x <- ctable21[1,1]
L <- x/(x+((n-x+1)*qf(0.95,(2*(n-x+1)),2*x))) * 100
U <- (x+1)*qf(0.95,(2*(x+1)),2*(n-x))/((n-x)+(x+1)*qf(0.95,(2*(x+1)),2*(n-x))) * 100
results["Sensitivity",1] <- paste0(round(L,2),"%, ",round(U,2),"%")
# Simple asymptotic
n <- sum(ctable21[,1])
phat <- 0.3
L <- (phat - qnorm(0.95)*sqrt((phat*(1-phat))/n))*100
U <- (phat + qnorm(0.95)*sqrt((phat*(1-phat))/n))*100
results["Sensitivity",2] <- paste0(round(L,2),"%, ",round(U,2),"%")
# Specificity
# Clopper-Pearson
n <- sum(ctable21[,2])
x <- ctable21[2,2]
L <- x/(x+((n-x+1)*qf(0.95,(2*(n-x+1)),2*x))) * 100
U <- (x+1)*qf(0.95,(2*(x+1)),2*(n-x))/((n-x)+(x+1)*qf(0.95,(2*(x+1)),2*(n-x))) * 100
results["Specificity",1] <- paste0(round(L,2),"%, ",round(U,2),"%")
# Simple asymptotic
n <- sum(ctable21[,2])
phat <- 0.936
L <- (phat - qnorm(0.95)*sqrt((phat*(1-phat))/n))*100
U <- (phat + qnorm(0.95)*sqrt((phat*(1-phat))/n))*100
results["Specificity",2] <- paste0(round(L,2),"%, ",round(U,2),"%")
```

```{r echo=FALSE}
kable(results)
```

The Clopper-Pearson CI for sensitivity is (8.73%,60.66%). The simple asymptotic CI for sensitivity is (6.16%,53.84%). The Clopper-Pearson CI for specificity is (88.75%, 96.78%). The simple asymptotic CI for specificity is (90.00%, 97.20%). 

In general, the normal approximation works best for large sample sizes. Although as a general rule of thumb the Central Limit Theorem applies to sample sizes over 30, the boostrap distribution of sensitivity was not normally distributed so I would use the exact confidence interval in this case. 

Confidence intervals are essentially the range for a parameter that is consistent with the data. So based on the exact confidence intervals, if we were to repeat this experiment many times, sensitivity for this test would be between 8.73% and 60.66% in 90% of those experiments.

\pagebreak

## e. Linear Regression

### i. Model Equation

$$
\hat{MeHg} = \hat{\beta_0} + \hat{\beta}_1X_{\text{fisherman}}+ \hat{\beta}_2X_{\text{fish meals per week}}+\hat{\beta}_3X_{\text{fish parts=1}}+\hat{\beta}_4X_{\text{fish parts=2}}+\hat{\beta}_5X_{\text{fish parts=3}}
$$

In the model above, $\hat{\beta}_1$ is the estimate for the effect of being a fisherman on mercury levels. $\hat{\beta}_2$ is the estimated effect of the number of fish meals per week on mercury levels. $\hat{\beta}_3$, $\hat{\beta}_4$, and $\hat{\beta}_5$ are the estimated effect of eating muscle tissue only, muscle tissue and sometimes the whole fish, or the whole fish (respectively). $\hat{\beta}_0$, the intercept, is the average mercury level for someone who is not a fisherman, eats 0 fish meals per week, and does not consume any fish parts.

### ii. Results

```{r echo=FALSE}
lin_mod <- lm(MeHg ~ factor(fisherman)+fishmlwk+factor(fishpart),data = fish)
results <- as.data.frame(round(summary(lin_mod)$coefficients,3))
rownames(results) <- c("Intercept","Fisherman = Yes",
                       "Fish Meals per Week","Fish Part = Muscle",
                       "Fish Part = Muscle and Whole",
                       "Fish Part = Whole")
results <- cbind(results,round(confint(lin_mod),3))
results <- results %>%
  unite("95% CI",`2.5 %`,`97.5 %`,remove = T,sep = ", ") %>%
  select(Estimate,"95% CI","Pr(>|t|)")
kable(results)
```

### iii. Summary

On average, being a fisherman increases mercury levels by 0.246 (95% CI: -1.221,1.714), but this relationship is not statistically significant (p = 0.740).

## f. Fishermen Who Eat 4 Meals of Whole Fish Each Week

### i. Average

$$
\textbf{a} = \begin{pmatrix}
1&1&4&0&0&1
\end{pmatrix}
$$
$$
\pmb\beta=\begin{pmatrix}
0.904&0.246&0.096&3.061&1.676&3.009
\end{pmatrix}
$$
$$
\hat{Y} = \textbf{a}^{\text{T}}\pmb\beta=4.543
$$
$$
\text{CI} = \hat{Y}\pm t_{\frac{\alpha}{2}}\sqrt{(MSE)\textbf{a}^{\text{T}}(\textbf{X}^{\text{T}}\textbf{X})^{-1}\textbf{a}}
$$

```{r include=FALSE}
a <- matrix(c(1,1,4,0,0,1))
b <- as.numeric(summary(lin_mod)$coefficients[,1])
yhat <- t(a)%*%b
mse <- mean(lin_mod$residuals^2)
t <- qt(0.1/2,133,lower.tail = F)
x <- model.matrix(lin_mod)
L <- yhat - t*sqrt(mse*(t(a)%*%(solve((t(x)%*%x)))%*%a))
U <- yhat + t*sqrt(mse*(t(a)%*%(solve((t(x)%*%x)))%*%a))
```

On average, fishermen who eat 4 meals of whole fish each week will have a mercury level of 4.546 (95% CI: 3.071,6.019).

### ii. Individual

$$
\hat{Y} = \textbf{a}^{\text{T}}\pmb\beta=4.543
$$
$$
\text{CI} = \hat{Y}\pm t_{\frac{\alpha}{2}}\sqrt{(MSE)(1+\textbf{a}^{\text{T}}(\textbf{X}^{\text{T}}\textbf{X})^{-1}\textbf{a})}
$$

```{r include=FALSE}
a <- matrix(c(1,1,4,0,0,1))
b <- as.numeric(summary(lin_mod)$coefficients[,1])
yhat <- t(a)%*%b
mse <- mean(lin_mod$residuals^2)
t <- qt(0.1/2,133,lower.tail = F)
x <- model.matrix(lin_mod)
L <- yhat - t*sqrt(mse*(1+(t(a)%*%(solve((t(x)%*%x)))%*%a)))
U <- yhat + t*sqrt(mse*(1+(t(a)%*%(solve((t(x)%*%x)))%*%a)))
```

An individual fisherman who eats 4 meals of whole fish each week will have a mercury level of 4.546 (95% CI: -0.011,9.102).

### iii. Prediction Interval vs. Confidence interval

The confidence interval above gives us information about the average mercury level for fishermen who eat 4 meals of whole fish each week in the current sample. However, the prediction interval refers to the mercury level for a theoretical new study participant. So because we are trying to make inference about a broader population, we need to account for some uncertainty in our estimators, which results in a wider interval.

\pagebreak

# Question 2

## a.

$$
log(Y_i^*)\sim N(\beta_0+\beta_1X_i,\sigma^2)
$$
$$
Yi = 1\text{ when }Y_i^* > l=0.001
$$
$$
Yi = 1\text{ when }log(Y_i^*) > log(l)
$$
$$
P(log(Y_i^*) > log(l)) = 1-P(log(Y_i^*)\leq log(l))
$$
$$
=1-P(\frac{log(Y_i^*)-\beta_0-\beta_1X_i}{\sigma}\leq\frac{log(l)-\beta_0-\beta_1X_i}{\sigma})=1-P(Z\leq\frac{log(l)-\beta_0-\beta_1X_i}{\sigma})
$$
$$
= 1 - \Phi(\frac{log(l)-\beta_0-\beta_1X_i}{\sigma})
$$
$$
\text{Set }P(log(Y_i^*) > log(l)) = \theta_i
$$
$$
Y_i\text{~ Bernoulli}(\theta_i)
$$

In order for this model to work, $\frac{log(l)-\beta_0-\beta_1X_i}{\sigma}$ must be between 0 and 1, so $0\leq log(l)-(\beta_0+\beta_1X_i)\leq\sigma$, which means $log(l)\geq(\beta_0+\beta_1X_i)$.

Next calculate the log likelihood of Yi:

$$
L(Y_i|\theta)=\prod_{i = 1}^{n}\theta_i^{Y_i}(1-\theta_i)^{1-Y_i}
$$
$$
logL(Y_i|\theta)=\sum_{i = 1}^{n}Y_ilog(\theta_i)+(1-Y_i)log(1-\theta_i)
$$
$$
= \sum_{i = 1}^{n}Y_ilog(1 - \Phi(\frac{log(l)-\beta_0-\beta_1X_i}{\sigma}))+(1-Y_i)log(\Phi(\frac{log(l)-\beta_0-\beta_1X_i}{\sigma}))
$$

In a Probit model like this, the standard normal can be used in place of a normal with arbitrary mean and SD without loss of generality, so the log-likelihood can be re-written in a more standard matrix form:

$$
logL(Y_i|\theta)=\sum_{i = 1}^{n}Y_ilog(\Phi(X_i^T\beta)))+(1-Y_i)log(1-\Phi(X_i^T\beta)))
$$

Define the log likelihood function in R and find MLEs using optim(), then calculate asymptotic variance using the Fisher Information Matrix (inverse Hessian):

```{r}
# Contamination as binary variable
pcbs$Yi <- ifelse(pcbs$contam.lev >= 0.001,1,0)
pcbs$Xi <- ifelse(pcbs$location == "Niagara",1,0)
# optim
minus_log_L_fun <- function(params) {
    b0 <- params[1]
    b1 <- params[2]
    log_L <- 
      sum(pcbs$Yi*(log(pnorm(b0+b1*pcbs$Xi)))+
            (1-pcbs$Yi)*(log(1-pnorm(b0+b1*pcbs$Xi))))    
    return (-log_L)
}
mle <- optim(runif(2), minus_log_L_fun, hessian = TRUE)
mle$par
I <- mle$hessian
var_Theta_probit <- diag(solve(I))
```

Use glm() to check the coefficient estimates:

```{r}
probit_mod <-
  glm(Yi ~ factor(location), family = binomial(link = "probit"), data = pcbs)
summary(probit_mod)$coefficients
```

## b.

Because $log(Y_i^*)$ is a standard normal distribution with a location and scale shift, we can rewrite the distribution as $log(Y_i^*)\sim \frac{1}{\sigma}\phi(\frac{log(Y_i^*)-(\beta_0+\beta_1X_i)}{\sigma})$. Next we define an indicator variable: 

$$
I(Y_i)=
\begin{cases}
  0, & \text{if}\ log(Y_i^*)\leq log(l) \\
  1, & \text{if}\ log(Y_i^*)>log(l)
\end{cases}
$$

The resulting likelihood is similar to above, but includes the normal PDF of $log(Y_i^*)$:

$$
L(log(Y_i^*)|\theta)=\prod_{i = 1}^{n}(\frac{1}{\sigma}\phi(\frac{log(Y_i^*)-(\beta_0+\beta_1X_i)}{\sigma})^{I(Y_i)}(\Phi(\frac{log(l)-\beta_0-\beta_1X_i}{\sigma}))^{1-I(Y_i)}
$$

$$
logL(log(Y_i^*)|\theta)=\sum_{i = 1}^{n}I(Y_i)(\frac{1}{\sigma}\phi(\frac{log(Y_i^*)-(\beta_0+\beta_1X_i)}{\sigma})+(1-I(Y_i))(\Phi(\frac{log(l)-\beta_0-\beta_1X_i}{\sigma}))
$$

So for observations where $log(Y_i^*)>log(l)$, the contribution to the likelihood function is the PDF of $log(Y_i^*)$. For observations that are below the detection threshold, the contribution to the likelihood is just the probability of being below the threshold as defined above. 

Define the log likelihood function in R and find MLEs using optim(), then calculate asymptotic variance using the Fisher Information Matrix (inverse Hessian):

```{r}
# Assign a finite lower censure threshold for those with contam.lev < 0.001
pcbs$log_Yi <- ifelse(log(pcbs$contam.lev) < log(0.001),-7,log(pcbs$contam.lev))
# Tobit function
tobit_fun <- function(par, X, y, limit) {
  sigma = exp(par[length(par)]) 
  beta = par[1:2]
  indicator = y > limit  
  XB = X %*% beta
  log_L = sum(indicator * log((1/sigma)*dnorm((y-XB)/sigma)) ) + 
    sum((1-indicator) * log(pnorm((XB-limit)/sigma, lower=F)))
  -log_L
}
initmod = lm(log_Yi ~ factor(location), data=pcbs)
X = model.matrix(initmod)
init = c(coef(initmod), log_sigma=log(summary(initmod)$sigma))

mle <- optim(par=init, tobit_fun, y=pcbs$log_Yi, X=X, limit=-6.9,hessian = T)
mle$par
I <- mle$hessian
var_Theta_tobit <- diag(solve(I))
```

This is a type I Tobit model, which can be checked using the AER package:

```{r message=FALSE}
tobit <- AER::tobit(contam.lev ~ factor(location), left = 0.001, 
                    data = pcbs, dist = "lognormal")
summary(tobit)$coefficients
```

## c.

Because the Tobit regression is on the log scale, the variance  needs to be exponentiated before comparison. Based on this is appears that the Tobit estimators have greater asymptotic variance than the Probit ones. 

```{r}
var_Theta_probit[1:2]/exp(var_Theta_tobit)[1:2]
```

## d. 

Assuming that log concentration is normally distributed, the estimated mean concentration will be approximately equal to the estimated median. The average log concentration at Fort Erie is -4.451 (95% CI: -5.010, -3.892), and the average log concentration at Niagara is -2.254 (95% CI: -2.801, -1.707). Both of these estimates are slightly lower than the empirical medians from the raw data (-3.912 and -2.003 respectively).

## e. 

```{r out.width='.49\\linewidth', fig.width=3, fig.height=3,fig.show='hold',fig.align='center'}
plot(fitted(tobit),resid(tobit,type = "response"), main = "Fitted vs Residuals",ylab = "rr",xlab = "yhat")
qqnorm(resid(tobit,type = "response"))
```

The residuals for this model are clearly not normally distributed, so the fit is not particularly good. 

### f. 

```{r eval=FALSE}
# Tobit function with variable sigma
tobit_fun <- function(par, X, y, limit) {
  a = par[3:4]
  AB = X %*% a
  sigma = exp(AB) 
  beta = par[1:2]
  indicator = y > limit  
  XB = X %*% beta
  log_L = sum(indicator * log((1/sigma)*dnorm((y-XB)/sigma)) ) + 
    sum((1-indicator) * log(pnorm((XB-limit)/sigma, lower=F)))
  -log_L
}
initmod = lm(log_Yi ~ factor(location), data=pcbs)
X = model.matrix(initmod)
init = c(coef(initmod), log_sigma=log(summary(initmod)$sigma))

mle <- optim(par=init, tobit_fun, y=pcbs$log_Yi, X=X, limit=-6.9,hessian = T)
mle$par
I <- mle$hessian
var_Theta_tobit_2 <- diag(solve(I))
```

Unfortunately I didn't have time to get this model to work, but the code above provides a rough outline of the approach. Assuming I was able to get reasonable MLEs and asymptotic variances, I would use a Wald test to check whether or not $a_1=0$. Under the null hypothesis, the asymptotic distribution of the test statistic is:

$$
W = \frac{(\hat{\theta}-\theta_0)^2}{var(\hat{\theta})}=\frac{\hat{a_1}^2}{var(\hat{a_1})}\sim \chi^2_1
$$

If this test rejects the null hypothesis that $a_1=0$, then it makes sense to use the model where the variance of the outcome also depends on the covariates. Otherwise I would use the simpler model from part b, because $a_1=0$ would indicate that the variability of the outcome is independent of the covariates.

### g. 

Based on the Tobit regression from part b (the model fit wasn't ideal, but it was better than the Probit model and the best I was able to come up with), there is significantly more pollution at Niagara compared to Fort Erie (Z = 5.511, p < 0.0001).

\pagebreak

# Question 3

## Analysis Plan

### Introduction

The data for this analysis are a subset of completers from an early HIV/AIDS clinical trial, in which patients with HIV were treated with monotherapy or combination/dual therapy. Previous studies have shown that lowering HIV viral load can slow progression to AIDS, so it is an important outcome in clinical trials. Unfortunately, the virus develops resistance to mono- and dual-drug therapies. 

The aim of this study is to examine the effect over time of mono- and dual-drug therapies on $log_{10}\text{(viral load)}$. Participants were treated with only one of the two therapies for 48 weeks, and $log_{10}\text{(viral load)}$ was measured at regular intervals during treatment. The primary outcome is the difference between treatment arms at week 48, and a secondary outcome is the difference at week 24. 

### Hypotheses

Primary null hypothesis: There will be no difference in $log_{10}\text{(viral load)}$ between treatment groups at week 48.

Secondary null hypothesis: There will be no difference in $log_{10}\text{(viral load)}$ between treatment groups at week 24.

### Data Description

Variable descriptions from the data dictionary provided:

* pid: patient identification number; range (9, 6861)

* week: study week (0, 2, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48)

* trt: treatment group (0=mono-therapy arm (AZT or 3TC, N=111), 1=dual arm (AZT+3TC, N=113)) 

* logvl: log10(viral load); range (2.0, 6.143)

Researchers work with viral load on the log scale so this variable does not need to be tranformed. Participant demographics and CD4 counts unavailable.

### Analysis Methods

Because this study is a repeated measures design, $log_{10}\text{(viral load)}$ is assumed to be correlated within subjects from week to week. Therefore, all models examined for the purpose of model selection will be linear mixed effect models with a random intercept for participant. 

First, models using time ("week") and its higher term polynomials will be examined, because the relationship between $log_{10}\text{(viral load)}$ and time is assumed to be non-linear. The highest order term to be included in the final model will be determined based on the Akaike information criterion (AIC) and polynomial orthogonal contrasts. Because higher order polynomial terms increase multicollinearity, the polynomial models will also be assessed by comparison of variance inflation factor (VIF). 

In addition to models treating time as a continuous covariate, models treating it as a categorical variable will also be assessed using AIC. Treating time as categorical would significantly reduce the risk of collinearity. This model may also make the most sense in terms of how the data were collected, since the weeks of the study can be considered in terms of categorical "bins" rather than as a truly continuous variable.

Once the most parsimonious model has been selected, differences between the two treatment groups at specific timepoints will be analyzed using linear contrasts. Assumptions of normality and homoscedasticity will be checked with diagnostic plots.

### Proposed Tables and Figures

The overall type 3 test of fixed effects and the results of linear contrasts will be reported in tables. Plots of the difference in means at each timepoint (between the groups), and the fitted values of the final model will also be included in the report.

Model selection information, full final model output, and residual plots will be included in the report appendix.

### Other Notes

This analysis is potentially biased due to the fact that it is a complete case analysis. For example, it's possible that only participants who experienced good outcomes completed the study. If possible it would be better to include all participants, even those with missing data. 

## Results

### Methods 

First, $log_{10}\text{(viral load)}$ was modeled with continuous time as the only covariate in order to get a sense of the relationship between time and $log_{10}\text{(viral load)}$. Based on polynomial contrasts, it appears that the effect of continuous time is significant up to the 10th degree (i.e. the model would need to include $week$,$week^2$,...,$week^{10}$). Models with high-order terms are very tricky to interpret, and the fact that each term in the model is a function of multiple other terms makes inference difficult (due to multicollinearity, which we try to avoid).

Because of these concerns with polynomial terms, time was modeled as a categorical variable instead. In some ways this makes more sense given the study design, because we don't know the exact length of time between baseline and a given measurement. Each $log_{10}\text{(viral load)}$ measure was essentially put in a categorical bin when it was recorded, so trying to model time as continuous doesn't make much sense to begin with (although it's always worth exploring these things). The time as categorical model was also better than all of the continuous time models based on AIC.

Models with and without a random slope for treatment group were also compared, and the model without a random slope had a better AIC. Based on this model selection process, the final model was a linear mixed effect model with a random intercept for participant and time treated as a categorical variable.

### Table 1: Type 3 Tests of Fixed Effects

```{r echo=FALSE}
time_mod_cat <- lme(logvl ~ trt*factor(week), data=hiv,random = ~1|pid)
time_mod_cat_noint <- lme(logvl ~ trt*factor(week)-1, data=hiv,random = ~1|pid)
type_3_results <- as.data.frame(anova(time_mod_cat_noint))
rownames(type_3_results) <- c("Treatment","Week","Treatment:Week")
type_3_results$`p-value` <- format.pval(type_3_results$`p-value`,
                                        digits = 3,eps=0.001)
kable(type_3_results)
```

Type 3 tests of fixed effects test whether or not variable is significant overall. The table above indicates that there was a significant effect for treatment and time, and that there was an interaction effect between them. 

### Table 2: Linear Contrast Results

```{r echo=FALSE}
t <- emmeans(time_mod_cat,~ trt*factor(week))
t <- as.data.frame(pairs(t,by = "week"))
t$p.value <- format.pval(t$p.value,digits = 3,eps=0.001)
```

```{r echo=FALSE}
kable(t)
```

Linear contrasts are a method of comparing specific groups based on a model. The table above includes tests of the difference between the mono- and dual-therapy groups at each week. So there was no difference between the groups at baseline, but the difference was significant at each of the following weeks. Here estimate is the difference between the groups, but it is reported as an absolute value and doesn't indicate the direction of the difference. At each timepoint the dual-therapy group had lower $log_{10}\text{(viral load)}$ than the mono-therapy group (see figures 1 and 2).

### Figure 1: Difference in Means between Treatment Groups

```{r echo=FALSE}
em_plot <- emmip(time_mod_cat, week~trt) +
  xlab("Therapy") + 
  scale_x_discrete(labels=c("Mono","Dual")) +
  ylab("Mean log10(viral load)") +
  theme_bw()
```

```{r echo=FALSE}
em_plot
```

Figure 1 shows the difference in mean $log_{10}\text{(viral load)}$ between treatment groups at each week. Clearly the dual-therapy group was always lower, but the difference was smaller at baseline and particarly large at weeks 2 and 4. 

### Figure 2: Model Results

```{r echo=FALSE}
plot_data <- as.data.frame(emmeans(time_mod_cat,~ trt*factor(week)))
mod_plot <- ggplot(plot_data,aes(x=week,y=emmean, group=trt)) + 
  geom_line(aes(color=trt)) +
  xlab("Week") +
  ylab("Mean log10(viral load)") +
  scale_color_discrete(name = "Therapy", labels = c("Mono","Dual"))+
  theme_bw()
```

```{r echo=FALSE}
mod_plot
```

Figure 2 shows the model means at each week, split by treatment group.

### Conclusion

At week 24, $log_{10}\text{(viral load)}$ was higher in the mono-therapy group compared to dual-therapy by 0.845 (95% CI: 0.6125, 1.077; p < 0.001). 

At week 48, $log_{10}\text{(viral load)}$ was higher in the mono-therapy group compared to dual-therapy by 0.745 (95% CI: 0.5125, 0.978; p < 0.001). 

\pagebreak

# Appendix

```{r}
# Load libraries
library(tidyverse)
library(knitr)
library(epiR)
library(lme4)
library(nlme)
library(AER)
library(emmeans)
```

```{r}
# Format HIV data
colnames(hiv) <- c("pid","trt","week","logvl")
hiv$trt <- as.factor(hiv$trt)
hiv$pid <- as.factor(hiv$pid)
```

# Question 1

## Number of meals involving fish as a positive test

```{r}
# Create indicator variables and response
fish$meal0 <- ifelse(fish$fishmlwk >= 0,1,0)
fish$meal1 <- ifelse(fish$fishmlwk >= 1,1,0)
fish$meal2 <- ifelse(fish$fishmlwk >= 2,1,0)
fish$meal3 <- ifelse(fish$fishmlwk >= 3,1,0)
fish$meal4 <- ifelse(fish$fishmlwk >= 4,1,0)
fish$meal7 <- ifelse(fish$fishmlwk >= 7,1,0)
fish$meal14 <- ifelse(fish$fishmlwk >= 14,1,0)
fish$meal21 <- ifelse(fish$fishmlwk >= 21,1,0)
fish$response <- ifelse(fish$MeHg >= 8,1,0)
# Create contingency tables
ctable0 <- table(factor(fish$meal0,levels=1:0),factor(fish$response,levels=1:0))
ctable1 <- table(factor(fish$meal1,levels=1:0),factor(fish$response,levels=1:0))
ctable2 <- table(factor(fish$meal2,levels=1:0),factor(fish$response,levels=1:0))
ctable3 <- table(factor(fish$meal3,levels=1:0),factor(fish$response,levels=1:0))
ctable4 <- table(factor(fish$meal4,levels=1:0),factor(fish$response,levels=1:0))
ctable7 <- table(factor(fish$meal7,levels=1:0),factor(fish$response,levels=1:0))
ctable14 <- table(factor(fish$meal14,levels=1:0),factor(fish$response,levels=1:0))
ctable21 <- table(factor(fish$meal21,levels=1:0),factor(fish$response,levels=1:0))
# Make results table
sens_spec_results <- as.data.frame(matrix(ncol = 2,nrow = 8))
colnames(sens_spec_results) <- c("Sensitivity","Specificity")
rownames(sens_spec_results) <- c(">=0",">=1",">=2",">=3",">=4",">=7",">=14",">=21")
```

```{r}
# Format results
sens_spec_results[">=0","Specificity"] <- 
  round(sensspec0$elements$specificity$est*100,1)
sens_spec_results[">=0","Sensitivity"] <- 
  round(sensspec0$elements$sensitivity$est*100,1)
sens_spec_results[">=1","Specificity"] <- 
  round(sensspec1$elements$specificity$est*100,1)
sens_spec_results[">=1","Sensitivity"] <- 
  round(sensspec1$elements$sensitivity$est*100,1)
sens_spec_results[">=2","Specificity"] <- 
  round(sensspec2$elements$specificity$est*100,1)
sens_spec_results[">=2","Sensitivity"] <- 
  round(sensspec2$elements$sensitivity$est*100,1)
sens_spec_results[">=3","Specificity"] <- 
  round(sensspec3$elements$specificity$est*100,1)
sens_spec_results[">=3","Sensitivity"] <- 
  round(sensspec3$elements$sensitivity$est*100,1)
sens_spec_results[">=4","Specificity"] <- 
  round(sensspec4$elements$specificity$est*100,1)
sens_spec_results[">=4","Sensitivity"] <- 
  round(sensspec4$elements$sensitivity$est*100,1)
sens_spec_results[">=7","Specificity"] <- 
  round(sensspec7$elements$specificity$est*100,1)
sens_spec_results[">=7","Sensitivity"] <- 
  round(sensspec7$elements$sensitivity$est*100,1)
sens_spec_results[">=14","Specificity"] <- 
  round(sensspec14$elements$specificity$est*100,1)
sens_spec_results[">=14","Sensitivity"] <- 
  round(sensspec14$elements$sensitivity$est*100,1)
sens_spec_results[">=21","Specificity"] <- 
  round(sensspec21$elements$specificity$est*100,1)
sens_spec_results[">=21","Sensitivity"] <- 
  round(sensspec21$elements$sensitivity$est*100,1)
```

## Bootstrap sampling

```{r}
# Vector for storing results
set.seed(1234)
B <- 10000
sens_results <- numeric(B)
spec_results <- numeric(B)
# Loop
for (i in 1:B) {
  meals <- sample(fish$fishmlwk,replace = T)
  meals <- ifelse(meals >= 21,1,0)
  response <- sample(fish$MeHg,replace = T)
  response <- ifelse(response >= 8,1,0)
  table <- table(factor(meals,levels=1:0),factor(response,levels=1:0))
  sens_results[i] <- (table[1,1]/sum(table[,1])) * 100
  spec_results[i] <- (table[2,2]/sum(table[,2])) * 100
}
```


## Mean, SE, and Bias From Bootstrap Distributions

```{r}
boot_results <- as.data.frame(matrix(ncol = 3,nrow = 2))
colnames(boot_results) <- c("Mean","Standard Error","Bias")
rownames(boot_results) <- c("Sensitivity","Specificity")
# Sensitivity
boot_results["Sensitivity","Mean"] <- mean(sens_results)
boot_results["Sensitivity","Standard Error"] <- 
  sd(sens_results)/sqrt(length(sens_results))
boot_results["Sensitivity","Bias"] <- 
  mean(sens_results) - sensspec21$elements$sensitivity$est*100
# Specificity
boot_results["Specificity","Mean"] <- mean(spec_results)
boot_results["Specificity","Standard Error"] <- 
  sd(spec_results)/sqrt(length(spec_results))
boot_results["Specificity","Bias"] <- 
  mean(spec_results) - sensspec21$elements$specificity$est*100
```

## 90% Bootstrap and Normal Percentile Confidence Intervals

```{r}
# Sensitivity
# Normal percentiles
L <- mean(sens_results) - (1.645 * sd(sens_results))
U <- mean(sens_results) + (1.645 * sd(sens_results))
# Specificity
# Normal percentiles
Lc <- mean(spec_results) - (1.645 * sd(spec_results))
Uc <- mean(spec_results) + (1.645 * sd(spec_results))
# Results table
results <- as.data.frame(matrix(ncol = 3,nrow = 2))
rownames(results) <- c("Sensitivity","Specificity")
colnames(results) <- c("Normal Percentile","Coverage","Bootstrap CI")
L <- round(L,2)
U <- round(U,2)
Lc <- round(Lc,2)
Uc <- round(Uc,2)
results["Sensitivity",] <- 
  c(paste0(L,"%, ",U,"%"),
    paste0(round(sum(sens_results < L)/B * 100,2),"%, ",
           round(sum(sens_results > U)/B * 100,2),"%"),
    paste0(paste(round(quantile(sens_results,c(0.05,0.95)),2),collapse = "%, "),"%"))
results["Specificity",] <- 
  c(paste0(Lc,"%, ",Uc,"%"),
    paste0(round(sum(spec_results < Lc)/B * 100,2),"%, ",
           round(sum(spec_results > Uc)/B * 100,2),"%"),
    paste0(paste(round(quantile(spec_results,c(0.05,0.95)),2),collapse = "%, "),"%"))
```

## 90% Confidence Intervals Using Exact and Asymptotic Methods

```{r}
# Sensitivity
# Clopper-Pearson
results <- as.data.frame(matrix(ncol = 2,nrow = 2))
rownames(results) <- c("Sensitivity","Specificity")
colnames(results) <- c("Clopper-Pearson","Simple Asymptotic")
n <- sum(ctable21[,1])
x <- ctable21[1,1]
L <- x/(x+((n-x+1)*qf(0.95,(2*(n-x+1)),2*x))) * 100
U <- (x+1)*qf(0.95,(2*(x+1)),2*(n-x))/((n-x)+(x+1)*qf(0.95,(2*(x+1)),2*(n-x))) * 100
results["Sensitivity",1] <- paste0(round(L,2),"%, ",round(U,2),"%")
# Simple asymptotic
n <- sum(ctable21[,1])
phat <- 0.3
L <- (phat - qnorm(0.95)*sqrt((phat*(1-phat))/n))*100
U <- (phat + qnorm(0.95)*sqrt((phat*(1-phat))/n))*100
results["Sensitivity",2] <- paste0(round(L,2),"%, ",round(U,2),"%")
# Specificity
# Clopper-Pearson
n <- sum(ctable21[,2])
x <- ctable21[2,2]
L <- x/(x+((n-x+1)*qf(0.95,(2*(n-x+1)),2*x))) * 100
U <- (x+1)*qf(0.95,(2*(x+1)),2*(n-x))/((n-x)+(x+1)*qf(0.95,(2*(x+1)),2*(n-x))) * 100
results["Specificity",1] <- paste0(round(L,2),"%, ",round(U,2),"%")
# Simple asymptotic
n <- sum(ctable21[,2])
phat <- 0.936
L <- (phat - qnorm(0.95)*sqrt((phat*(1-phat))/n))*100
U <- (phat + qnorm(0.95)*sqrt((phat*(1-phat))/n))*100
results["Specificity",2] <- paste0(round(L,2),"%, ",round(U,2),"%")
```

## Linear Regression

```{r}
lin_mod <- lm(MeHg ~ factor(fisherman)+fishmlwk+factor(fishpart),data = fish)
results <- as.data.frame(round(summary(lin_mod)$coefficients,3))
rownames(results) <- c("Intercept","Fisherman = Yes",
                       "Fish Meals per Week","Fish Part = Muscle",
                       "Fish Part = Muscle and Whole",
                       "Fish Part = Whole")
results <- cbind(results,round(confint(lin_mod),3))
results <- results %>%
  unite("95% CI",`2.5 %`,`97.5 %`,remove = T,sep = ", ") %>%
  select(Estimate,"95% CI","Pr(>|t|)")
```

## Confidence/Prediction Intervals

### Average

```{r}
a <- matrix(c(1,1,4,0,0,1))
b <- as.numeric(summary(lin_mod)$coefficients[,1])
yhat <- t(a)%*%b
mse <- mean(lin_mod$residuals^2)
t <- qt(0.1/2,133,lower.tail = F)
x <- model.matrix(lin_mod)
L <- yhat - t*sqrt(mse*(t(a)%*%(solve((t(x)%*%x)))%*%a))
U <- yhat + t*sqrt(mse*(t(a)%*%(solve((t(x)%*%x)))%*%a))
```

### Individual

```{r}
a <- matrix(c(1,1,4,0,0,1))
b <- as.numeric(summary(lin_mod)$coefficients[,1])
yhat <- t(a)%*%b
mse <- mean(lin_mod$residuals^2)
t <- qt(0.1/2,133,lower.tail = F)
x <- model.matrix(lin_mod)
L <- yhat - t*sqrt(mse*(1+(t(a)%*%(solve((t(x)%*%x)))%*%a)))
U <- yhat + t*sqrt(mse*(1+(t(a)%*%(solve((t(x)%*%x)))%*%a)))
```

# Question 2

All code included in report

# Question 3

## Model selection

```{r}
# Confirm time is nonlinear
# Linear
time_mod <- lme(logvl ~ week, data=hiv,random = ~1|pid)
plot(time_mod)
# Try quadratic
time_mod <- lme(logvl ~ week+I(week^2), data=hiv,random = ~1|pid)
summary(time_mod)$tTable
vif(time_mod)
# Cubic
time_mod <- lme(logvl ~ week+I(week^2)+I(week^3), 
                data=hiv,random = ~1|pid,method = "ML")
vif(time_mod)
# Quartic
time_mod <- lme(logvl ~ week+I(week^2)+I(week^3)+I(week^4), 
                data=hiv,random = ~1|pid,method = "ML")
vif(time_mod)
# Polynomials
time_mod_poly <- lme(logvl ~ poly(week,13),data=hiv,random = ~1|pid,method = "ML")
summary(time_mod_poly)$tTable
# Compare categorical time to continuous time with quadratic
time_mod <- lme(logvl ~ trt*(week+I(week^2)), data=hiv,random = ~1|pid,method = "ML")
time_mod_cat <- lme(logvl ~ trt*factor(week), data=hiv,random = ~1|pid,method = "ML")
anova(time_mod,time_mod_cat) # AIC much better for categorical time, and makes sense with design
# Compare with random slope for treatment
time_mod_cat_slope <- lme(logvl ~ trt*factor(week), data=hiv,random = ~1+trt|pid,method = "ML")
anova(time_mod_cat,time_mod_cat_slope) # slightly better without random slope
# Full output for final model
time_mod_cat <- lme(logvl ~ trt*factor(week), data=hiv,random = ~1|pid)
summary(time_mod_cat)$tTable
# Residuals 
plot(time_mod_cat)
qqnorm(time_mod_cat)
# Odd residuals most likely due to higher frequency of values between 2 and 2.5
hist(hiv$logvl)
# Check without values < 2.5
time_mod_cat_check <- lme(logvl ~ trt*factor(week), data=hiv[hiv$logvl>2.5,],random = ~1|pid)
plot(time_mod_cat_check) # Still not ideal, but a little better
qqnorm(time_mod_cat_check)
# Although we're assuming that logvl is normally distributed at each week, 
# this doesn't appear to be the case.
```

## Final model and test of overall effect

```{r}
time_mod_cat <- lme(logvl ~ trt*factor(week), data=hiv,random = ~1|pid)
time_mod_cat_noint <- lme(logvl ~ trt*factor(week)-1, data=hiv,random = ~1|pid)
type_3_results <- as.data.frame(anova(time_mod_cat_noint))
rownames(type_3_results) <- c("Treatment","Week","Treatment:Week")
type_3_results$`p-value` <- format.pval(type_3_results$`p-value`,
                                        digits = 3,eps=0.001)
```

## Linear Contrasts

```{r}
t <- emmeans(time_mod_cat,~ trt*factor(week))
t <- as.data.frame(pairs(t,by = "week"))
t$p.value <- format.pval(t$p.value,digits = 3,eps=0.001)
```

## Figure 1

```{r}
em_plot <- emmip(time_mod_cat, week~trt) +
  xlab("Therapy") + 
  scale_x_discrete(labels=c("Mono","Dual")) +
  ylab("Mean log10(viral load)") +
  theme_bw()
```

## Figure 2

```{r}
plot_data <- as.data.frame(emmeans(time_mod_cat,~ trt*factor(week)))
mod_plot <- ggplot(plot_data,aes(x=week,y=emmean, group=trt)) + 
  geom_line(aes(color=trt)) +
  xlab("Week") +
  ylab("Mean log10(viral load)") +
  scale_color_discrete(name = "Therapy", labels = c("Mono","Dual"))+
  theme_bw()
```

## Confidence intervals

```{r}
confint(pairs(emmeans(time_mod_cat,~ trt*factor(week)),by="week"))
```

## Session Info

```{r}
sessionInfo()
```