---
title: "BIOS 7659 Homework 6"
author: "Tim Vigers"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE,dpi = 600)
knitr::opts_knit$set(root.dir="C:/Users/tim/Documents/GitHub/School/Statistical Genomics")
library(cqn)
library(edgeR)
library(biomaRt)
library(RUVSeq)
library(tidyverse)
library(flextable)
```

```{r}
data("montgomery.subset")
data("uCovar")
```

# 1. Differential Expression

## a) Calculate RPKM and perform a t test

RPKM stands for reads per kilobases per million reads and is calculated by $$\frac{r_g}{l_g T}=\frac{\text{# of mapped reads}}{\text{length in Kb}*\text{total mapped reads in millions}}:$$

```{r}
lg = uCovar$length / 1000
t = sum(unlist(montgomery.subset))
rpkm = montgomery.subset/(lg*t)
```

Do a standard t test between the groups for each gene:

```{r}
# T test for each row
t_tests = apply(rpkm,1,function(x){
  group1 = as.numeric(x[1:5])
  group2 = as.numeric(x[6:10])
  if(var(group1)==0 | var(group2)==0){ # Skip those with constant values 
    return(c(NA,NA))
  } else {
    t <- t.test(group1,group2)
    return(c(t$statistic,t$p.value))
  }
})
# Format and print
t_tests = as.data.frame(t(t_tests))
t_tests = t_tests %>% rownames_to_column() %>% 
  set_names(c("Gene","T","p")) %>% arrange(desc(abs(T))) 

t_tests %>% head(10) %>% flextable(.) %>% 
  set_caption("Top 10 Genes by t-statistic") %>% autofit(.)
```

## b) Plot the histogram of p-values

```{r}
hist(t_tests$p,main = "Histogram of p values",xlab = "p")
```

Normally we would expect a uniform distribution of p values, but this distribution appears to have a peak at around 0.3 and another at p = 1. My guess is that this is because we have only filtered genes with all 0 counts, but kept other genes with counts so low that they are effectively 0. 

## c) Filter genes by total counts

# DOESN'T DGELIST AUTOMATICALLY INCLUDE lib.size
with the total reads per subject?

```{r}
# Remove genes with low counts
filtered = montgomery.subset[rowSums(montgomery.subset)>=10,]
# Create edgeR object
filtered_dge = DGEList(filtered,group = c(rep(1,5),rep(2,5)))
```

## d) Calculate TMM normalization factors

```{r}
norm = calcNormFactors(filtered_dge)
autofit(flextable(norm$samples))
```

The effective library sizes are generally similar to the column sums because the normalization factors are fairly close to 1. A normalization factor > 1 increases the library size, which is similar to downscaling the counts (and vice versa for factors < 1). So, the effective library size for sample 6 is increased by about 115%. Conversely, the effective library size for sample 5 is decreased by approximately 90%, which suggests that there are a small number of high-count sequences that need to be adjusted for.

## e) Use the `estimateDisp()` function to calculate the common, trended and tagwise dispersions

```{r}
filtered_dge = estimateDisp(filtered_dge)
```

The common dispersion estimate is approximately `r round(filtered_dge$common.dispersion,3)`. Plot the tagwise dispersion estimate for each gene vs. the average log counts per million:

# IS IT OKAY TO USE THE BUILT IN FUNCTION THAT PLOTS ON SQUARE ROOT SCALE?

```{r}
plotBCV(filtered_dge)
```

The common dispersion estimate only seems to work well for a narrow range of log CPM around 4. It appears to underestimate dispersion for the lower count genes and overestimate the higher average count genes.

## f) Fit the negative binomial model

### Using the common dispersion estimate

```{r}
et <- exactTest(filtered_dge,dispersion = "common")
top_common <- topTags(et) %>% as.data.frame(.) %>% 
  rownames_to_column(.,var = "Gene")
autofit(flextable(top_common))
```

### Using the tag-wise dispersion estimates

```{r}
et <- exactTest(filtered_dge,dispersion = "tagwise")
top_tagwise <- topTags(et) %>% as.data.frame(.) %>% 
  rownames_to_column(.,var = "Gene")
autofit(flextable(top_tagwise))
```

There are only `r length(intersect(top_tagwise$Gene,top_common$Gene))` overlapping genes in the top 10 table for the two methods.Also, the top genes as determined by the common dispersion estimate approach appear to be driven more by fold change than those that are most significant using the tagwise method, because the table is essentially in decreasing order of logFC (with a couple of minor exceptions).

## g) Extract the raw counts 

### For the top 10 genes based on the common dispersion

```{r}
top_common_counts = filtered_dge$counts[top_common$Gene,] %>%
  as.data.frame(.) %>% rownames_to_column(var = "Gene")
set_table_properties(flextable(top_common_counts),
                     width = .5, layout = "autofit")
```

# Most of these top genes have...

### For the top 10 genes based on tagwise dispersion

```{r}
top_tagwise_counts = filtered_dge$counts[top_tagwise$Gene,] %>%
  as.data.frame(.) %>% rownames_to_column(var = "Gene")
set_table_properties(flextable(top_tagwise_counts),
                     width = .5, layout = "autofit")
```

# These are more evenly spread...

### Get Ensembl information for the top genes

#### Based on common dispersion

```{r}
ensembl = useEnsembl(biomart="ensembl", dataset="hsapiens_gene_ensembl")
en = getBM(attributes=c('ensembl_gene_id','description'), 
           filters ='ensembl_gene_id', values = top_common_counts$Gene, 
           mart = ensembl)
set_table_properties(flextable(en),
        width = .75, layout = "autofit")
```

#### Based on tagwise dispersion

```{r}
en = getBM(attributes=c('ensembl_gene_id','description'), 
           filters ='ensembl_gene_id', values = top_tagwise_counts$Gene, 
           mart = ensembl)
set_table_properties(flextable(en),
        width = .75, layout = "autofit")
```

# 2. Remove Unwanted Variation.

## a) Create a design matrix that includes an intercept and group indicator

```{r}
group = c(rep(1,5),rep(2,5))
design = model.matrix(~group)
filtered_dge = DGEList(filtered)
filtered_dge = calcNormFactors(filtered_dge,"upperquartile")
filtered_dge = estimateDisp(filtered_dge,design = design)
glm_fit = glmFit(filtered_dge,
                 dispersion = filtered_dge$common.dispersion)
glm_lrt = glmLRT(glm_fit)$table
glm_lrt$PValue_FDR = p.adjust(glm_lrt$PValue,"fdr")
```


